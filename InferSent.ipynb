{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "eligibility_criteria_filename = '../../cardio_data_final_14thOct.csv'\n",
    "output_eligibility_criteria_filename = 'cardio_data_final_14thOct_output_exclusion.csv'\n",
    "\n",
    "regex = re.compile('exclusion criteria:(.*)')\n",
    "regex2 = re.compile('1\\. .*2\\. .*')\n",
    "lines = []\n",
    "lines2 = []\n",
    "\n",
    "with open(eligibility_criteria_filename) as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            line_count = 1\n",
    "        else:\n",
    "            ec = row[4]\n",
    "            nctid = row[0]\n",
    "            ec_split = []\n",
    "            x = regex.search(ec)\n",
    "            if x is not None:\n",
    "                ec = x.group(1)\n",
    "                if regex2.search(ec) is not None:\n",
    "                    lines2.append([nctid,ec])\n",
    "                    continue\n",
    "                ec_split = ec.split(' - ')\n",
    "                if len(ec_split) <= 4:\n",
    "                    continue\n",
    "                for each in ec_split:\n",
    "                    if each == '':\n",
    "                        continue\n",
    "                    lines.append([nctid,each])\n",
    "\n",
    "\n",
    "with open(output_eligibility_criteria_filename, 'w') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerows(lines)\n",
    "\n",
    "with open('refined.csv', 'w') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerows(lines2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_datapath = \"../EligibilityCriteria.csv\"\n",
    "ec_data = pd.read_csv(ec_datapath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_datapath = \"../ClinicalNotes.csv\"\n",
    "notes_data = pd.read_csv(notes_datapath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusion_ec_filepath = \"../cardio_data_final_14thOct_output_exclusion.csv\"\n",
    "exclusion_ec_data = pd.read_csv(exclusion_ec_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce number of ec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('ec_filtered.txt' , 'w')\n",
    "ec_dict = {}\n",
    "for row in range(ec_data.shape[0]):\n",
    "\ttry:\n",
    "\t\ttrial_id = ec_data.iloc[row,0]\n",
    "\t\tec = ec_data.iloc[row,1]\n",
    "\t\tf.write(trial_id + '::' + ec + '\\n')\n",
    "\t\tif trial_id not in ec_dict:\n",
    "\t\t\tec_dict[trial_id] = 1\n",
    "\t\t\tif len(ec_dict) == 50:\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\texcept UnicodeDecodeError:\n",
    "\t\tprint row\n",
    "\n",
    "ec_dict = None\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select ec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce number of Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('notes_filtered.txt' , 'w')\n",
    "notes_dict = {}\n",
    "for row in range(notes_data.shape[0]):\n",
    "\ttry:\n",
    "\t\tnote_id = notes_data.iloc[row,0]\n",
    "\t\tnote = notes_data.iloc[row,2]\n",
    "\t\tf.write(str(note_id) + '::' + note + '\\n')\n",
    "\t\tif note_id not in notes_dict:\n",
    "\t\t\tnotes_dict[note_id] = 1\n",
    "\t\t\tif len(notes_dict) == 100:\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\texcept UnicodeDecodeError:\n",
    "\t\tprint row\n",
    "\n",
    "notes_dict = None\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FK reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a skull x-ray , ultrasound scan and subsequent mri scan of the brain did not show any apparent distortion apart from depression and concavity in the left parietal bone  .  the purpose of this case report is to raise awareness of this possible , mild outcome of this little - known entity , which may mimic caput succedaneum ( moulding of the presenting part in the birth canal during natural delivery ) , and to provide a historical and embryological background  .   background  amniotic band disruption syndrome is a rare entity which occurs in 1 in 1200 to 1 in 15 000 live births  .  1 it may cause a myriad of deformities of fetal body parts from mild defects in limbs to severe craniofacial defects incompatible with life  .  the spectrum of defects includes disruption , deformation and malformation of different body parts due to interference from the amniotic bands at different stages of organogenesis  .  2 the syndrome is also described as adam complex ( for ‘ amniotic deformities , adhesions , mutilation ’ ) or amniotic band disruption complex ( abdc ) for its nature of presentation  .  since tropin described the condition in 1968 , 3 many questions regarding this syndrome remain unanswered because of its rarity and complex mechanism  .  this case is unique in its presentation as it mimics caput succedaneum without any neurological defect  .  this type of presentation has not been described before in the medical literature  .   case presentation  a girl , born at 38 weeks of gestation by vaginal delivery of normal duration of labour , presented with a large caput over the left parietal region ( figure 1a , b )  .  the mother was a 32 - year - old primigravida without any significant medical illness  .  there was no family history of consanguinity or chronic illness  .  the pregnancy was uneventful and antenatal scans were reported as normal  .  the mother had a history of premature rupture of the membrane of more than 24 h and had prophylactic antibiotics  .  the baby did not cry immediately after birth  .  the apgar score at 1 min was 5 , and this increased to 9 after five inflation breaths  .  her blood sugar was 6 . 1 mmol / litre  .  her birth weight was 1960 g ( 9th to 25th centile ) and head circumference was 29 cm ( 9th centile )  .  she was pink , handling well and moving all her limbs spontaneously  .  her oxygen saturation on air was 99 %  .  she did not have any respiratory distress , visible congenital anomaly or audible cardiac murmur  .  there was no frontal bossing , ear abnormality or hypertelorism  .  musculoskeletal and neurological examination of the baby was normal  .  the craniofacial contours of the parents were unremarkable  .   the circumference of the asymmetric swelling of the scalp was 26 cm  .  a clear wide demarcation line was present between the swelling and the vessels of the scalp  .  the skin over the swelling appeared darker than the rest of the scalp  .  cranial sutures including the saggital suture could not be felt due to the swelling  .  the newborn was given nasogastric feeding and intravenous cefotaxime  .   investigations  her blood investigations were all within normal limits  .  a skull x-ray showed moulding of the skull bone over the left parietotemporal region ( figures 2 and 3 )  .  no overriding or fracture was found except soft tissue swelling overlying the vertex  .  an ultrasound scan of the brain showed symmetrical lateral ventricles in both hemispheres with falx at the midline  .  a collection of fluid of 0 . 7 – 1 cm in diameter was found over the calvaria , which was suggestive of caput succedaneum  .   a subsequent mri showed the left hemicranium was distorted with relative preservation on the right side ( figure 4 )  .  there was some concavity of the right parietal bone at the edge of caput succedaneum and similar inbowing of the lateral cranium on the left side , which was suggestive of modelling by an amniotic band  .   differential diagnosis  treatment  outcome and follow - up  discussion  though the exact aetiology of abdc is unknown , two main pathogenetic mechanisms are proposed  .  exogenous theory suggests early amnion rupture leading to a fibrous band that can entrap fetal body part ( figure 5 )  .  the endogenous theory suggests vascular compromise  .  genetic factors might operate in some cases  .   moerman et al described three types of lesions in this complex : ( a ) constrictive tissue bands ( shrivelled amniotic strands ) , ( b ) amniotic adhesions ( fusion between disrupted body part and intact amniotic membrane ) and ( c ) limb – body wall complex  .  6 according to their observations , most of the craniofacial defects occur as a result of a vascular disruption sequence with or without cephaloamniotic adhesions , unlike the case described here that had the clear mark of a constriction band without significant vascular compromise  .   an accurate diagnosis may be achieved by looking for the major features of amniotic band syndrome , and a routine chromosome study and placental examination in cases with multiple congenital anomalies  .  27  though encephalocele , clefts , distortion and dislocation of craniofacial structures have been described as presentations of craniofacial defect related to this syndrome in the medical literature , 5 distorted hemicranium ( mimicking caput succedaneum ) without any neurological defect has never been described previously  .  the outcome of the syndrome depends on the gravity of malformation  .  termination of pregnancy is considered in cases of severe craniofacial or visceral abnormality  .  successful limb salvage by fetoscopic release of an amniotic band has been reported  .  most of the minor craniofacial defects require multiple surgical procedures to restore function , with significant compromise to satisfactory cosmesis \n"
     ]
    }
   ],
   "source": [
    "f = open('notes_read_metrics.txt' , 'w')\n",
    "notes_dict = {}\n",
    "prev_note_id = None\n",
    "sentences = []\n",
    "for row in range(notes_data.shape[0]):\n",
    "    try:\n",
    "        note_id = notes_data.iloc[row,0]\n",
    "        note = notes_data.iloc[row,2]\n",
    "        \n",
    "        if prev_note_id != note_id:\n",
    "            if prev_note_id is not None:\n",
    "                note_line = ' . '.join(sentences)\n",
    "                print note_line\n",
    "                sentences_num = len(sentences)\n",
    "                words = note_line.split(' ')\n",
    "                words = [x for x in words if x.strip()!='.' and x.strip()!='']\n",
    "                words_num = len(words)\n",
    "                letters_num = sum([len(x) for x in words])\n",
    "                score = 206.835 - (1.015 * (float(words_num)/sentences_num)) - (84.6 * (float(letters_num)/words_num))\n",
    "                #print words\n",
    "                break\n",
    "                print words_num,sentences_num,letters_num,words_num,score\n",
    "                f.write(str(prev_note_id) + '::' + str(score) + '\\n')\n",
    "            sentences = []\n",
    "            prev_note_id = note_id\n",
    "        sentences.append(note)\n",
    "\n",
    "    except UnicodeDecodeError:\n",
    "        print row\n",
    "\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = open('notes_hist.csv' , 'w')\n",
    "notes_dict = {}\n",
    "prev_note_id = None\n",
    "sentences = []\n",
    "for row in range(notes_data.shape[0]):\n",
    "    try:\n",
    "        note_id = notes_data.iloc[row,0]\n",
    "        note = notes_data.iloc[row,2]\n",
    "        \n",
    "        if prev_note_id != note_id:\n",
    "            if prev_note_id is not None:\n",
    "                f.write(str(prev_note_id) + ',' + str(len(sentences)) + '\\n')\n",
    "            sentences = []\n",
    "            prev_note_id = note_id\n",
    "        sentences.append(note)\n",
    "\n",
    "    except UnicodeDecodeError:\n",
    "        print row\n",
    "\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('ec_hist.csv' , 'w')\n",
    "prev_trial_id = None\n",
    "sentences = []\n",
    "f.write('Trial id,length\\n')\n",
    "for row in range(ec_data.shape[0]):\n",
    "    try:\n",
    "        trial_id = ec_data.iloc[row,0]\n",
    "        ec = ec_data.iloc[row,1]\n",
    "        \n",
    "        if prev_trial_id != trial_id:\n",
    "            if prev_trial_id is not None:\n",
    "                f.write(str(prev_trial_id) + ',' + str(len(sentences)) + '\\n')\n",
    "            sentences = []\n",
    "            prev_trial_id = trial_id\n",
    "        sentences.append(ec)\n",
    "\n",
    "    except UnicodeDecodeError:\n",
    "        print row\n",
    "\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create input.txt and index.txt\n",
    "input.txt - <note>\\t<ec>\n",
    "index.txt - <trial_id>\\t<note_d>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_ec = open('ec_filtered.txt')\n",
    "f_note = open('notes_filtered.txt')\n",
    "\n",
    "out_f = open('input.txt', 'w')\n",
    "out_fi = open('index.txt', 'w')\n",
    "index = {}\n",
    "count = 0\n",
    "for line_ec in f_ec:\n",
    "    if line_ec.strip() == '':\n",
    "        continue\n",
    "    trial_id, ec = line_ec.strip().split('::', 1)\n",
    "    f_note = open('notes_filtered.txt')\n",
    "    for line_note in f_note:\n",
    "        if line_note.strip() == '':\n",
    "            continue\n",
    "        note_id, note = line_note.strip().split('::', 1)\n",
    "        out_f.write(note + '\\t' + ec + '\\n')\n",
    "        out_fi.write(trial_id + '\\t' + note_id + '\\n')\n",
    "        \n",
    "    f_note.close()\n",
    "out_fi.close()\n",
    "out_f.close()\n",
    "f_ec.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create files\n",
    "max line numbers in each file must be 100000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_line_num = 100000\n",
    "out_f = open('input.txt')\n",
    "count = 0\n",
    "f_num = 1\n",
    "for line in out_f:\n",
    "    line = line.strip()\n",
    "    if count == 0:\n",
    "        f = open('input/input_'+str(f_num)+'.txt' , 'w')\n",
    "        f_num += 1\n",
    "    count += 1\n",
    "    f.write(line+'\\n')\n",
    "    if count == max_line_num:\n",
    "        f.close()\n",
    "        count = 0\n",
    "\n",
    "out_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '../../30-03-2019/mednli/out/out'\n",
    "output = open('../../30-03-2019/mednli/out/out.txt', 'w')\n",
    "for i in range(1,37):\n",
    "    f_name = input_dir + str(i)\n",
    "    with open(f_name) as f:\n",
    "        for line in f:\n",
    "            res,_ = line.strip().split('::',1)\n",
    "            output.write(res+'\\n')\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '../../30-03-2019/mednli/input/input_'\n",
    "output = open('../../30-03-2019/mednli/input/input.txt', 'w')\n",
    "c = 0\n",
    "for i in range(1,37):\n",
    "    f_name = input_dir + str(i) + '.txt'\n",
    "    with open(f_name) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            output.write(line+'\\n')\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = open('../../30-03-2019/mednli/input/input.txt')\n",
    "output_file_path = open('../../30-03-2019/mednli/out/out.txt')\n",
    "out = open('../../30-03-2019/mednli/result1.txt', 'w')\n",
    "for line in input_file_path:\n",
    "    note,ec = line.strip().split('\\t')\n",
    "    class_ = output_file_path.readline().strip()\n",
    "    out.write(note+'$######$'+ec+'$######$'+class_+'\\n')\n",
    "out.close()\n",
    "input_file_path.close()\n",
    "output_file_path.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = open('../../30-03-2019/mednli/result1.txt')\n",
    "index_file = open('index.txt')\n",
    "out = open('../../30-03-2019/mednli/result.txt', 'w')\n",
    "\n",
    "for line in result_file:\n",
    "    line = line.strip()\n",
    "    trial_id,note_id = index_file.readline().strip().split('\\t',1)\n",
    "    out.write(trial_id+'$######$'+note_id + '$######$' + line + '\\n')\n",
    "\n",
    "out.close()\n",
    "result_file.close()\n",
    "index_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = open('../../30-03-2019/mednli/ec_note_match.txt', 'w')\n",
    "with open('../../30-03-2019/mednli/result.txt') as f:\n",
    "    prev_trial_id_note_id = None\n",
    "    ent_count = 0\n",
    "    con_count = 0\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        trial_id,note_id,note,ec,class_ = line.split('$######$')\n",
    "        note_id = '0'*(8-len(note_id)) + note_id\n",
    "        \n",
    "        trial_id_note_id = trial_id+'$######$'+note_id\n",
    "        if prev_trial_id_note_id != trial_id_note_id:\n",
    "            if prev_trial_id_note_id is not None:\n",
    "                out.write(prev_trial_id_note_id+'$######$'+str(float(ent_count)/(ent_count+con_count))+'\\n')\n",
    "            ent_count = 0\n",
    "            con_count = 0\n",
    "            prev_trial_id_note_id = trial_id_note_id\n",
    "        if class_ == 'Entailment':\n",
    "            ent_count += 1\n",
    "        else:\n",
    "            con_count+=1\n",
    "if prev_trial_id_note_id == trial_id_note_id:\n",
    "    out.write(prev_trial_id_note_id+'$######$'+str(float(ent_count)/(ent_count+con_count))+'\\n')\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = open('../../30-03-2019/mednli/trial_note.txt', 'w')\n",
    "with open('../../30-03-2019/mednli/ec_note_match_sorted.txt') as f:\n",
    "    prev_trial_id_note_id = None\n",
    "    count = 0\n",
    "    summ = 0\n",
    "    note_list = []\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        trial_id,note_id,match = line.split('$######$')\n",
    "        match = float(match)\n",
    "        \n",
    "        trial_id_note_id = trial_id + '$######$' + note_id\n",
    "        if prev_trial_id_note_id != trial_id_note_id:\n",
    "            if prev_trial_id_note_id is not None:\n",
    "                out.write(prev_trial_id_note_id+'$######$'+str(float(summ)/count)+'\\n')\n",
    "            #note_list = []\n",
    "            count = 0\n",
    "            summ = 0\n",
    "            prev_trial_id_note_id = trial_id_note_id\n",
    "        count += 1\n",
    "        summ += match\n",
    "        #if match > THRESHOLD:\n",
    "        #    note_list.append(note_id)\n",
    "if prev_trial_id_note_id == trial_id_note_id:\n",
    "    out.write(prev_trial_id_note_id+'$######$'+str(float(summ)/count)+'\\n')\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = open('../../30-03-2019/mednli/trial_notelist_0.5.txt', 'w')\n",
    "THRESHOLD = 0.6\n",
    "with open('../../30-03-2019/mednli/trial_note.txt') as f:\n",
    "    prev_trial_id = None\n",
    "    note_list = []\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        trial_id,note_id,match = line.split('$######$')\n",
    "        match = float(match)\n",
    "        \n",
    "        if prev_trial_id != trial_id:\n",
    "            if prev_trial_id is not None:\n",
    "                note_list = [str(int(x)) for x in note_list]\n",
    "                out.write(prev_trial_id+'::'+','.join(note_list)+'\\n')\n",
    "            note_list = []\n",
    "            prev_trial_id = trial_id\n",
    "        if match > THRESHOLD:\n",
    "            note_list.append(note_id)\n",
    "if prev_trial_id == trial_id:\n",
    "    note_list = [str(int(x)) for x in note_list]\n",
    "    out.write(prev_trial_id+'::'+','.join(note_list)+'\\n')\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = open(\"../../30-03-2019/mednli/trial_notelist_0.5.txt\")\n",
    "ec_dict = {}\n",
    "for line in in_file:\n",
    "    trialid,note_id_list = line.strip().split(\"::\",1)\n",
    "    note_id_list = note_id_list.split(',')\n",
    "    ec_dict[trialid] = note_id_list\n",
    "in_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = open(\"../../30-03-2019/mednli/trial_notelist_0.5_hist.csv\", 'w')\n",
    "#ec_dict = {}\n",
    "out_file.write('Trialid,Note id list\\n')\n",
    "for trialid in ec_dict:\n",
    "    out_file.write(trialid + ',' + str(len(ec_dict[trialid]))+'\\n')\n",
    "out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('ec_filtered_exclusion.txt' , 'w')\n",
    "\n",
    "for row in range(exclusion_ec_data.shape[0]):\n",
    "\ttry:\n",
    "\t\ttrial_id = exclusion_ec_data.iloc[row,0]\n",
    "\t\tec = exclusion_ec_data.iloc[row,1]\n",
    "\t\tif trial_id in ec_dict:\n",
    "\t\t\tf.write(trial_id + '::' + ec + '\\n')\n",
    "            \n",
    "\texcept UnicodeDecodeError:\n",
    "\t\tprint row\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_file = open('ec_filtered_exclusion.txt')\n",
    "f = open('note_filtered_exclusion.txt' , 'w')\n",
    "f_i = open('exclusion_index.txt' , 'w')\n",
    "\n",
    "\n",
    "for line in ec_file:\n",
    "    trialid,ec = line.strip().split(\"::\",1)\n",
    "    note_list = ec_dict[trialid]\n",
    "    note_file = open('notes_filtered.txt')\n",
    "    for line_n in note_file:\n",
    "        if len(line_n.strip())==0:\n",
    "            continue\n",
    "        note_id, sent = line_n.strip().split(\"::\",1)\n",
    "        if note_id in note_list:\n",
    "            f.write(sent+'\\t'+ec+'\\n')\n",
    "            f_i.write(trialid+'::'+note_id+'\\n')\n",
    "    note_file.close()\n",
    "    \n",
    "ec_file.close()\n",
    "f.close()\n",
    "f_i.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_line_num = 100000\n",
    "out_f = open('note_filtered_exclusion.txt')\n",
    "count = 0\n",
    "f_num = 1\n",
    "for line in out_f:\n",
    "    line = line.strip()\n",
    "    if count == 0:\n",
    "        f = open('input/input_ec_'+str(f_num)+'.txt' , 'w')\n",
    "        f_num += 1\n",
    "    count += 1\n",
    "    f.write(line+'\\n')\n",
    "    if count == max_line_num:\n",
    "        f.close()\n",
    "        count = 0\n",
    "\n",
    "out_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '../../30-03-2019/mednli/out/out_ec_'\n",
    "output = open('../../30-03-2019/mednli/out/out_ec.txt', 'w')\n",
    "for i in range(1,5):\n",
    "    f_name = input_dir + str(i)\n",
    "    with open(f_name) as f:\n",
    "        for line in f:\n",
    "            res,_ = line.strip().split('::',1)\n",
    "            output.write(res+'\\n')\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '../../30-03-2019/mednli/input/input_ec_'\n",
    "output = open('../../30-03-2019/mednli/input/input_ec.txt', 'w')\n",
    "c = 0\n",
    "for i in range(1,5):\n",
    "    f_name = input_dir + str(i) + '.txt'\n",
    "    with open(f_name) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            output.write(line+'\\n')\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = open('../../30-03-2019/mednli/input/input_ec.txt')\n",
    "output_file_path = open('../../30-03-2019/mednli/out/out_ec.txt')\n",
    "out = open('../../30-03-2019/mednli/result1_ec.txt', 'w')\n",
    "for line in input_file_path:\n",
    "    note,ec = line.strip().split('\\t')\n",
    "    class_ = output_file_path.readline().strip()\n",
    "    out.write(note+'$######$'+ec+'$######$'+class_+'\\n')\n",
    "out.close()\n",
    "input_file_path.close()\n",
    "output_file_path.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = open('../../30-03-2019/mednli/result1_ec.txt')\n",
    "index_file = open('exclusion_index.txt')\n",
    "out = open('../../30-03-2019/mednli/result_ec.txt', 'w')\n",
    "\n",
    "for line in result_file:\n",
    "    line = line.strip()\n",
    "    trial_id,note_id = index_file.readline().strip().split('::',1)\n",
    "    out.write(trial_id+'$######$'+note_id + '$######$' + line + '\\n')\n",
    "\n",
    "out.close()\n",
    "result_file.close()\n",
    "index_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = open('../../30-03-2019/mednli/ec_note_match_exclusion.txt', 'w')\n",
    "with open('../../30-03-2019/mednli/result_ec.txt') as f:\n",
    "    prev_trial_id_note_id = None\n",
    "    ent_count = 0\n",
    "    con_count = 0\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        trial_id,note_id,note,ec,class_ = line.split('$######$')\n",
    "        note_id = '0'*(8-len(note_id)) + note_id\n",
    "        \n",
    "        trial_id_note_id = trial_id+'$######$'+note_id\n",
    "        if prev_trial_id_note_id != trial_id_note_id:\n",
    "            if prev_trial_id_note_id is not None:\n",
    "                out.write(prev_trial_id_note_id+'$######$'+str(float(ent_count)/(ent_count+con_count))+'\\n')\n",
    "            ent_count = 0\n",
    "            con_count = 0\n",
    "            prev_trial_id_note_id = trial_id_note_id\n",
    "        if class_ == 'Contradiction':\n",
    "            ent_count += 1\n",
    "        else:\n",
    "            con_count+=1\n",
    "if prev_trial_id_note_id == trial_id_note_id:\n",
    "    out.write(prev_trial_id_note_id+'$######$'+str(float(ent_count)/(ent_count+con_count))+'\\n')\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = open('../../30-03-2019/mednli/trial_note_exclusion.txt', 'w')\n",
    "with open('../../30-03-2019/mednli/ec_note_match_exclusion_sorted.txt') as f:\n",
    "    prev_trial_id_note_id = None\n",
    "    count = 0\n",
    "    summ = 0\n",
    "    note_list = []\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        trial_id,note_id,match = line.split('$######$')\n",
    "        match = float(match)\n",
    "        \n",
    "        trial_id_note_id = trial_id + '$######$' + note_id\n",
    "        if prev_trial_id_note_id != trial_id_note_id:\n",
    "            if prev_trial_id_note_id is not None:\n",
    "                out.write(prev_trial_id_note_id+'$######$'+str(float(summ)/count)+'\\n')\n",
    "            #note_list = []\n",
    "            count = 0\n",
    "            summ = 0\n",
    "            prev_trial_id_note_id = trial_id_note_id\n",
    "        count += 1\n",
    "        summ += match\n",
    "        #if match > THRESHOLD:\n",
    "        #    note_list.append(note_id)\n",
    "if prev_trial_id_note_id == trial_id_note_id:\n",
    "    out.write(prev_trial_id_note_id+'$######$'+str(float(summ)/count)+'\\n')\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = open('../../30-03-2019/mednli/trial_notelist_0.5_exclusion.txt', 'w')\n",
    "THRESHOLD = 0.2\n",
    "with open('../../30-03-2019/mednli/trial_note_exclusion.txt') as f:\n",
    "    prev_trial_id = None\n",
    "    note_list = []\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        trial_id,note_id,match = line.split('$######$')\n",
    "        match = float(match)\n",
    "        \n",
    "        if prev_trial_id != trial_id:\n",
    "            if prev_trial_id is not None:\n",
    "                note_list = [str(int(x)) for x in note_list]\n",
    "                out.write(prev_trial_id+'::'+','.join(note_list)+'\\n')\n",
    "            note_list = []\n",
    "            prev_trial_id = trial_id\n",
    "        if match > THRESHOLD:\n",
    "            note_list.append(note_id)\n",
    "if prev_trial_id == trial_id:\n",
    "    note_list = [str(int(x)) for x in note_list]\n",
    "    out.write(prev_trial_id+'::'+','.join(note_list)+'\\n')\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_in = open('../../30-03-2019/mednli/trial_notelist_0.5.txt')\n",
    "f_ex = open('../../30-03-2019/mednli/trial_notelist_0.5_exclusion.txt')\n",
    "out = open('../../30-03-2019/mednli/result_final.txt', 'w')\n",
    "\n",
    "f_in_dict = {}\n",
    "for line in f_in:\n",
    "    trial_id,note_list = line.strip().split('::',1)\n",
    "    note_list = set()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
